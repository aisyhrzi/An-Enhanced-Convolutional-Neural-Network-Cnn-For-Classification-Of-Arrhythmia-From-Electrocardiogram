# -*- coding: utf-8 -*-
"""TENSORFLOW

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JdkCecLL8WtHINK2LdrFeITCS_gS6QhH
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Rescaling
from tensorflow.keras.backend import clear_session
import gc

# Clear previous sessions and free memory
clear_session()
gc.collect()

# Define directories
train_dir = '/content/drive/My Drive/ecg_classification_master/tomeksmote_resize_image_split/training'
val_dir = '/content/drive/My Drive/ecg_classification_master/tomeksmote_resize_image_split/validation'
test_dir = '/content/drive/My Drive/ecg_classification_master/tomeksmote_resize_image_split/testing'

IMAGE_SIZE = 224
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

# Load datasets first (without map/prefetch) to get class names
raw_train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    seed=123,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='categorical'
)
class_names = raw_train_ds.class_names
num_classes = len(class_names)
print("Classes:", class_names)

raw_val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    seed=123,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='categorical'
)

raw_test_ds = tf.keras.utils.image_dataset_from_directory(
    test_dir,
    seed=123,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='categorical'
)

# Normalize pixel values [0,255] -> [0,1]
normalization_layer = Rescaling(1./255)

# Apply normalization and prefetch
train_ds = raw_train_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(buffer_size=AUTOTUNE)
validation_ds = raw_val_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(buffer_size=AUTOTUNE)
test_ds = raw_test_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(buffer_size=AUTOTUNE)

# Define Mohonta CNN architecture
def create_mohonta_cnn(input_shape=(224, 224, 3), num_classes=5):
    model = models.Sequential([
        layers.Conv2D(128, (11, 11), strides=4, activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(3, 3), strides=2),

        layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(3, 3), strides=2),

        layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(3, 3), strides=2),

        layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2), strides=2),

        layers.Flatten(),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

# Create and compile model
model = create_mohonta_cnn(input_shape=(224, 224, 3), num_classes=num_classes)
model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Model summary
model.summary()

# Train the model
history = model.fit(
    train_ds,
    validation_data=validation_ds,
    epochs=10,
    verbose=1
)

# Evaluate on test dataset
test_loss, test_acc = model.evaluate(test_ds)
print(f"Test accuracy: {test_acc*100:.2f}%")

# Save the model
model_save_path = '/content/drive/My Drive/ecg_classification_master/tomeksmote_tensorflow_cnn_model.h5'
model.save(model_save_path)
print(f"Model saved at: {model_save_path}")

# Save history
import pickle
history_path = '/content/drive/My Drive/ecg_classification_master/tomeksmote_history_base.pkl'
with open(history_path, 'wb') as f:
    pickle.dump(history.history, f)
print(f"Training history saved at: {history_path}")