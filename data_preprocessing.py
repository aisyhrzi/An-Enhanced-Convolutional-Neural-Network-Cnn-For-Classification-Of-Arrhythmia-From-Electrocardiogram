# -*- coding: utf-8 -*-
"""Data Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JdkCecLL8WtHINK2LdrFeITCS_gS6QhH
"""

## Phase 2: Data Preprocessing
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pywt
from sklearn.preprocessing import MinMaxScaler
import os

# Configure plots
plt.rcParams["figure.figsize"] = (12, 6)
plt.rcParams['lines.linewidth'] = 1
plt.rcParams['axes.grid'] = True

# Denoise function using Daubechies wavelet 4
def denoise(data):
    w = pywt.Wavelet('db4')
    maxlev = pywt.dwt_max_level(len(data), w.dec_len)
    threshold = 0.04  # Threshold for filtering

    coeffs = pywt.wavedec(data, 'db4', level=maxlev)
    for i in range(1, len(coeffs)):
        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))

    datarec = pywt.waverec(coeffs, 'db4')

    return datarec

# Function to plot the original and denoised signals
def plot_denoised_vs_original(original_data, denoised_data, filename):
    plt.figure(figsize=(15, 5))

    # Plot original signal
    plt.plot(original_data, label='Original ECG', color='blue')

    # Plot denoised signal
    plt.plot(denoised_data, label='Denoised ECG', color='red')

    plt.title(f'Original and Denoised ECG Signal from {filename}')
    plt.xlabel('Sample Index')
    plt.ylabel('Amplitude (mV)')
    plt.legend()
    plt.show()

# Path to the training data
training_set_ids = [100,104,114,118,124,203,208,213,223,230]
path = '/content/drive/My Drive/ecg_classification_master/dataset'

# Directory to save segmented denoised data
output_dir = '/content/drive/My Drive/ecg_classification_master/denoised'
os.makedirs(output_dir, exist_ok=True)

# Read and process the files
try:
    filenames = next(os.walk(path))[2]
except StopIteration:
    print("Directory is empty or path is incorrect.")
    filenames = []

# Split and save .csv and .txt files
records = list()
annotations = list()
if filenames:
    filenames.sort()
    for f in filenames:
        filename, file_extension = os.path.splitext(f)

        # Extract numeric ID from the filename
        numeric_part = ''.join(filter(str.isdigit, filename))
        if numeric_part and int(numeric_part) in training_set_ids:
            if file_extension == '.csv':
                records.append(path + '/' + filename + file_extension)
            elif file_extension == '.txt':
                annotations.append(path + '/' + filename + file_extension)

print(records[0] if records else "No CSV files found.")
print(annotations[0] if annotations else "No TXT files found.")

# Process each dataset
for record_file in records:
    dataset_id = os.path.splitext(os.path.basename(record_file))[0]
    print(f"Processing dataset {dataset_id}")

    # Load the ECG data
    data = pd.read_csv(record_file, header=None, skiprows=1)

    # Extract the 'MLII' lead data
    ecg_data = data[1].apply(pd.to_numeric, errors='coerce').dropna().values

    # Apply denoising to the ECG data
    denoised_data = denoise(ecg_data)

    # Plot the original and denoised signals for the entire data
    plot_denoised_vs_original(ecg_data, denoised_data, f'{dataset_id}.csv')

    # Segment the denoised data into 1000-sample segments
    segment_size = 1000
    num_segments = len(denoised_data) // segment_size

    # Collect all segments into a list
    segments = []
    for i in range(num_segments):
        start_idx = i * segment_size
        end_idx = start_idx + segment_size
        segment = denoised_data[start_idx:end_idx]
        segments.append(segment)

    # Convert the list of segments into a DataFrame
    segments_df = pd.DataFrame(segments)

    # Save the segmented denoised data to a CSV file
    denoised_segments_file_path = os.path.join(output_dir, f'{dataset_id}_denoised_segmented.csv')
    segments_df.to_csv(denoised_segments_file_path, header=False, index=False)

    print(f"Denoised and segmented data has been saved to {denoised_segments_file_path}")